{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gslib_formate(welllogpath=\"W51_por_scale_up\"):\n",
    "    content=\"\"\n",
    "    heads=[]\n",
    "    with open(welllogpath, 'r', encoding='utf-8') as file:\n",
    "        idx=0\n",
    "        headnum=9999\n",
    "        heads=[]\n",
    "        bodys=\"\"\n",
    "        for line in file:\n",
    "            if idx==1:\n",
    "                headnum=int(line.strip())\n",
    "            if idx>1 and idx<headnum+2:\n",
    "                heads.append(line.strip())\n",
    "            idx=idx+1\n",
    "    with open(welllogpath, 'r', encoding='utf-8') as file:\n",
    "        split_str=heads[len(heads)-1]\n",
    "        content = file.read()\n",
    "        contents=content.split(split_str)\n",
    "        bodys=contents[1][1:]\n",
    "    df = pd.read_csv(StringIO(bodys),header=None, sep=' ')\n",
    "    df = df.iloc[:, :-1]\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.columns=heads\n",
    "    return df\n",
    "\n",
    "def pd2Gslib(S2X4_welllog_por2,df_all,petrel_formate_savepath='petrel_formate.txt'):\n",
    "    df=df_all\n",
    "    df1=df[['i_index unit1 scale1', 'j_index unit1 scale1','k_index unit1 scale1','x_coord unit1 scale1', 'y_coord unit1 scale1','z_coord unit1 scale1']]\n",
    "\n",
    "    merged_df = pd.merge(df1, S2X4_welllog_por2, on=['i_index unit1 scale1', 'j_index unit1 scale1','k_index unit1 scale1','x_coord unit1 scale1', 'y_coord unit1 scale1','z_coord unit1 scale1'], how='outer')\n",
    "    merged_df=merged_df.fillna(-99)\n",
    "    merged_df\n",
    "\n",
    "    merged_df.to_csv(petrel_formate_savepath, sep=' ', index=False,header=False)\n",
    "    head_list=merged_df.columns.tolist()\n",
    "    head_list.insert(0, str(len(merged_df.columns.tolist())))\n",
    "    head_list.insert(0, \"PETREL: Properties\")\n",
    "    head_str=\"\\n\".join(head_list)\n",
    "    str_txt=head_str+\"\\n\"\n",
    "    with open(petrel_formate_savepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        str_txt=str_txt+content\n",
    "    with open(petrel_formate_savepath, 'w', encoding='utf-8') as file:\n",
    "        file.write(str_txt)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626641, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zyytxx\\AppData\\Local\\Temp\\ipykernel_100828\\3833195692.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  S2X4_welllog_por['S2X4_POR unit1 scale1']=S2X4_welllog_por['POR unit1 scale1']\n",
      "C:\\Users\\zyytxx\\AppData\\Local\\Temp\\ipykernel_100828\\3833195692.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  S2X4_welllog_por['S2X4_FACIES unit1 scale1']=S2X4_welllog_por['FACIES unit1 scale1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1612, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=read_gslib_formate(welllogpath=\"./all_samples/W51_por_scale_up\")\n",
    "print(df.shape)\n",
    "#S2X4的layer是18-24\n",
    "S2X4_zone=df[(df['Zones(hierarchy) unit1 scale1'] > 17) & (df['Zones(hierarchy) unit1 scale1'] < 25)]\n",
    "S2X4_zone[['i_index unit1 scale1', 'j_index unit1 scale1', 'k_index unit1 scale1','x_coord unit1 scale1', 'y_coord unit1 scale1', 'z_coord unit1 scale1','Zones(hierarchy) unit1 scale1']].to_csv(\"./all_samples/unknown_points.csv\",index=False)\n",
    "S2X4_welllog_por=df[(df['Zones(hierarchy) unit1 scale1'] > 17) & (df['Zones(hierarchy) unit1 scale1'] < 25)& (df['POR unit1 scale1'] >-1)]\n",
    "S2X4_welllog_por['S2X4_POR unit1 scale1']=S2X4_welllog_por['POR unit1 scale1']\n",
    "S2X4_welllog_por['S2X4_FACIES unit1 scale1']=S2X4_welllog_por['FACIES unit1 scale1']\n",
    "S2X4_welllog_por2=S2X4_welllog_por[['i_index unit1 scale1','j_index unit1 scale1', 'k_index unit1 scale1','x_coord unit1 scale1','y_coord unit1 scale1','z_coord unit1 scale1','S2X4_FACIES unit1 scale1','S2X4_POR unit1 scale1']]\n",
    "S2X4_welllog_por2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2Gslib(S2X4_welllog_por2,df,petrel_formate_savepath='./all_samples/petrel_formate.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共井的个数是[289]口井！\n",
      "总样本个数： (1612, 8)\n",
      "训练样本个数: 192 (1040, 8)\n",
      "测试样本个数: 97 (572, 8)\n"
     ]
    }
   ],
   "source": [
    "S2X4_welllog_por2 = S2X4_welllog_por2.sort_values(by=['i_index unit1 scale1', 'j_index unit1 scale1', 'k_index unit1 scale1'])\n",
    "grouped_df = S2X4_welllog_por2.groupby(['i_index unit1 scale1', 'j_index unit1 scale1'])\n",
    "print(\"总共井的个数是[{}]口井！\".format(str(len(grouped_df))))\n",
    "\n",
    "train_group=[]\n",
    "test_group=[]\n",
    "splitsize=0.3\n",
    "for idx, _group in enumerate(grouped_df):\n",
    "    num_to_sample = int(len(grouped_df)/(len(grouped_df) *splitsize))\n",
    "    if idx%num_to_sample==0:\n",
    "        test_group.append(_group)\n",
    "    else:\n",
    "        train_group.append(_group)\n",
    "\n",
    "train_group2 = [group for _, group in train_group]\n",
    "train_df=pd.concat(train_group2)\n",
    "train_df.to_csv(\"./train/known_points_train_{}.csv\".format(str(1-splitsize)),index=False)\n",
    "test_group2 = [group for _, group in test_group]\n",
    "test_df=pd.concat(test_group2)\n",
    "test_df.to_csv(\"./test/known_points_test_{}.csv\".format(str(splitsize)),index=False)\n",
    "unknown_points_grid=df[(df['Zones(hierarchy) unit1 scale1'] > 17) & (df['Zones(hierarchy) unit1 scale1'] < 25)][['i_index unit1 scale1', 'j_index unit1 scale1', 'k_index unit1 scale1', 'x_coord unit1 scale1', 'y_coord unit1 scale1', 'z_coord unit1 scale1']]\n",
    "unknown_points_grid.to_csv(\"./all_samples/unknown_points_grid.csv\",index=False)\n",
    "\n",
    "\n",
    "print(\"总样本个数：\",S2X4_welllog_por2.shape)\n",
    "print(\"训练样本个数:\",len(train_group),train_df.shape)\n",
    "print(\"测试样本个数:\",len(test_group),test_df.shape)\n",
    "pd2Gslib(train_df,df,petrel_formate_savepath='./train/petrel_Gslib_formate_train_{}.txt'.format(str(1-splitsize)))\n",
    "pd2Gslib(test_df,df,petrel_formate_savepath='./test/petrel_Gslib_formate_test_{}.txt'.format(str(splitsize)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "def pd2vtk(df):\n",
    "    min_x=df[\"x_coord unit1 scale1\"].min()\n",
    "    min_y=df[\"y_coord unit1 scale1\"].min()\n",
    "    points = vtk.vtkPoints()\n",
    "    scalars = vtk.vtkFloatArray()\n",
    "    vtk_save_path=\"S2X4_welllog_por.vtk\"\n",
    "    for index, row in S2X4_welllog_por.iterrows():\n",
    "        x=row[\"x_coord unit1 scale1\"]-min_x\n",
    "        y=row[\"y_coord unit1 scale1\"]-min_y\n",
    "        z=row[\"z_coord unit1 scale1\"]\n",
    "        v=row[\"POR unit1 scale1\"]   \n",
    "        points.InsertNextPoint(x, y, z)\n",
    "        scalars.InsertNextTuple1(v)\n",
    "    vtk_p = vtk.vtkPolyData()\n",
    "    vtk_p.SetPoints(points)\n",
    "    scalars.SetName(\"porosity\")\n",
    "    vtk_p.GetPointData().AddArray(scalars)\n",
    "    vtk_p.GetPointData().SetActiveScalars(\"porosity\")\n",
    "\n",
    "    logWriter = vtk.vtkPolyDataWriter()\n",
    "    logWriter.SetFileName(vtk_save_path)\n",
    "    logWriter.SetInputData(vtk_p)\n",
    "    logWriter.Write()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('torch38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b69bc1f9e1f1f65de9988c0ea2a3ce73f7622d377ab8320ccd5dc120069c42ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
